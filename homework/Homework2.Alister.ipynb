{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYD DAT 4 Lab 2 - Visualisation and Regression\n",
    "\n",
    "##Homework - Due 29th April 2016\n",
    "\n",
    "#### Setup\n",
    "* Signup for an AWS account\n",
    "\n",
    "#### Communication\n",
    "* Imagine you are trying to explain to someone what Linear Regression is - but they have no programming/maths experience? How would you explain the overall process, what a p-value means and what R-Squared means?\n",
    "* Read the paper [Useful things to know about machine learning]( https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf). \n",
    "    * What have we covered so far from this paper? \n",
    "    * Explain sections 6-13 in your own words\n",
    "\n",
    "#### Machine Learning\n",
    "* Read chapters 3 and 6 of Introduction to Statistical Learning\n",
    "* Describe 3 ways we can select what features to use in a model\n",
    "* Complete the first 3 exercises from Chapter 3 in Python\n",
    "\n",
    "#### Course Project\n",
    "* For the following setup a new github repository for your project and share it with Matt and Ian over Slack.\n",
    "* Load the data you have gathered for your project into Python and run some summary statistics over the data. Are there any interesting features of the data that jump out? (Include the code)\n",
    "* Draft/Sketch on paper (or wireframe) some data visualisations that would be useful for you to explore your data set\n",
    "* Are there any regresion or clustering techniques you could use in your project? Write them down (with the corresponding scikit learn function) and what you think you would get out of it.\n",
    "\n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework2_ian_hansel.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setup\n",
    "* Signup for AWS - COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communication\n",
    "### Linear Regression Explanation\n",
    "* Linear Regression is a model that tries to estimate how a specific numberic value reacts as another independent numeric value, that it relies upon, fluctuates.\n",
    "\n",
    "### Useful Things to know about Machine Learning\n",
    "a) So far in the GA Data Science course we have covered the topic of generalization and the problem of overfitting. Also, we have gone over the difficulities of machine learning as dimensionality expands. As mentioned in this article, feature selection is very important but is ultimately trumped by having more data. Finally, we have addressed the virtue of simplicity in models.\n",
    "\n",
    "b)\n",
    "#### INTUITION FAILS IN HIGH DIMENSIONS\n",
    "\n",
    "As dimensionality is increased, the required amount of data to cover the rapidly expanding input space also increases, making generalization more difficult.\n",
    "\n",
    "\n",
    "#### THEORETICAL GUARANTEES ARE NOT WHAT THEY SEEM\n",
    "\n",
    "Guarantees are useful in machine learning to help understand model design and guide practical applications, but must be used with a does of sceptism.\n",
    "\n",
    "\n",
    "#### FEATURE ENGINEERING IS THE KEY\n",
    "\n",
    "Raw data may not present easily usable features and the data scientist's role is transform the data into useful features via cleaning and other processes.\n",
    "\n",
    "\n",
    "#### MORE DATA BEATS A CLEVERER ALGORITHM\n",
    "\n",
    "Regardless of an algorithm's complexity, it can be easier to obtain a better result in machine learning by obtaining a larger amount of data.\n",
    "\n",
    "\n",
    "#### LEARN MANY MODELS, NOT JUST ONE\n",
    "By learning a variety of models, you can tackle a wider range of problems and more easily create ensembles to hone more complex problems that require a higher degree of accuracy.\n",
    "\n",
    "#### SIMPLICITY DOES NOT IMPLY ACCURACY\n",
    "Although simple hypotheses do not guarantee more accuracy, simplicity does have other benefits such as increased interporability that mean the should be preferred.\n",
    "\n",
    "#### REPRESENTABLE DOES NOT IMPLY LEARNABLE\n",
    "Just because something can be represented, it may still be very difficult to find the true function, especially in the case where there is many local optima.\n",
    "\n",
    "#### CORRELATION DOES NOT IMPLY CAUSATION\n",
    "It is difficult to declare causation absolutely but because much of the data in machine learning is obervational, even a discovered correlation may be worth investigating further and be of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "### 3 ways to select a model\n",
    "1) LASSO REGRESSION - By employing Lasso regression we can eliminate all but the most important features and mainatain a relatively useful model.\n",
    "\n",
    "2) SUBSET SELECTION - Create various regression models using all combinations of available features to minimise computational expense and reduce the risk of overfit.\n",
    "\n",
    "3) PRINCIPAL COMPONENT ANALYSIS - This method aims to fit as much of the variation into a low-dimensional representation which then help to identify the most useful features in explaining the dependent variable.\n",
    "\n",
    "### Chapter 3 Exercises\n",
    "\n",
    "1. Describe the null hypotheses to which the p-values given in Table 3.4 correspond. Explain what conclusions you can draw based on these p-values. Your explanation should be phrased in terms of sales, TV, radio, and newspaper, rather than in terms of the coefficients of the linear model.\n",
    "\n",
    "The null hypotheses for the p values depicted in Table 3.4 is that the given coefficient is equal to zero. As the TV and radio p values are very close to zero, the corresponding coefficients are considered to be signficant determinents of the sales and thus changing them will impact sales. The newspaper p value indicates that altering the newspaper advertising spend is not going to have a signifcant impact on sales.\n",
    "\n",
    "2. Carefully explain the differences between the KNN classifier and KNN regression methods.\n",
    "\n",
    "The KNN classifier method is for classifying qualitative data. However, KNN regression is a non-parametric approach to regression that will often outperform linear regression as it does not assume the form of the data.\n",
    "\n",
    "3. Suppose we have a data set with five predictors, X1 = GPA, X2 = IQ, X3 = Gender (1 for Female and 0 for Male), X4 = Interaction between GPA and IQ, and X5 = Interaction between GPA and Gender. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get βˆ0 = 50, βˆ1 = 2 0 , βˆ 2 = 0 . 0 7 , βˆ 3 = 3 5 , βˆ 4 = 0 . 0 1 , βˆ 5 = − 1 0 .\n",
    "(a) Which answer is correct, and why?\n",
    "i. ForafixedvalueofIQandGPA,malesearnmoreonaverage than females.\n",
    "ii. For a fixed value of IQ and GPA, females earn more on average than males.\n",
    "iii. ForafixedvalueofIQandGPA,malesearnmoreonaverage than females provided that the GPA is high enough.\n",
    "iv. For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough.\n",
    "(b) Predict the salary of a female with IQ of 110 and a GPA of 4.0.\n",
    "(c) True or false: Since the coefficient for the GPA/IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
